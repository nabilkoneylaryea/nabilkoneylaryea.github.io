This week was an interesting one for sure. I felt Like I was finally in the midst of my development work and it didn't end with my ROS work. After making the final touches to my multicamera ROS package and verifying the functionality again, I switched gears to some computer vision work.

I began by running code published from different computer vision papers and blogs to get a practical idea of how activity recognition worked programmatically. This was a very daunting task, since my prior knowledge of deep learning was extremely limited. Regardless, I forged ahead.

Since things were working nothing made sense, naturally. I launched an investigation immediately, turning to the Pytorch documentation to understand how data is represented as Tensors and how models are defined and represented in different ways. This process was extensive, but my knowledge of how computer vision models, especially CNN based architectures, process visual data was deepened extraordinarily.

Aside from these learnings, I continued literature review and started looking more into the datasets and evaluation metrics that are commonly used to train computer vision models for activity recognition. This week was a big one for my literature review process because I created and presented a slide deck on a particular paper that discussed novel training scheme. I was worried at first, but I successfully contextualized the paper with an interactive exercise, described motivations and research goals, explained the methods and results, and even answered questions about the architecture used!!

This was truly a big win for me because I finally felt like I understood the esoteric language in papers from some of the top computer vision conferences IN THE WORLD.
